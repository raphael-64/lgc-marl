# LGC-MARL Training Architecture

## Progressive Depth Evolution (Core Innovation)

```
                         WIDE EXPLORATION → DEEP EXPLOITATION

    Stage 1                                                          Stage 11
    16 candidates                                                    1 champion
    100 ep each                                                      4000 episodes
        │                                                                 │
        ▼                                                                 ▼
    ┌─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┐                                ┌───┐
    │█│█│█│█│█│█│█│█│█│█│█│█│█│█│█│█│  ◄── Many diverse graphs       │███│
    └─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┘      Quick evaluation          │███│
                    │                                                 │███│
                    │ Select top + evolve                             │███│
                    ▼                                                 │███│
            ┌─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┐                            │███│
            │█│█│█│█│█│█│█│█│█│█│█│█│█│█│  14 candidates             │███│
            └─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┘  150 episodes              │███│
                        │                                             │███│
                        ▼                                             │███│
                ┌─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┐                            │███│
                │█│█│█│█│█│█│█│█│█│█│█│█│  12 candidates             │███│
                └─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┘  200 episodes              │███│
                          │                                           │███│
                          ▼                                           │███│
                    ┌─┬─┬─┬─┬─┬─┬─┬─┬─┬─┐                            │███│
                    │█│█│█│█│█│█│█│█│█│█│  10 candidates             │███│
                    └─┴─┴─┴─┴─┴─┴─┴─┴─┴─┘  250 episodes              │███│
                            │                                         │███│
                            ▼                                         │███│
                      ┌─┬─┬─┬─┬─┬─┬─┬─┐                              │███│
                      │█│█│█│█│█│█│█│█│    8 candidates              │███│
                      └─┴─┴─┴─┴─┴─┴─┴─┘    300 episodes              │███│
                              │                                       │███│
                              ▼                                       │███│
                        ┌─┬─┬─┬─┬─┬─┐                                │███│
                        │█│█│█│█│█│█│      6 candidates              │███│
                        └─┴─┴─┴─┴─┴─┘      400 episodes              │███│
                              │                                       │███│
                              ▼                                       │███│
                          ┌─┬─┬─┬─┬─┐                                │███│
                          │█│█│█│█│█│      5 candidates              │███│
                          └─┴─┴─┴─┴─┘      500 episodes              │███│
                              │                                       │███│
                              ▼                                       │███│
                           ┌─┬─┬─┬─┐                                 │███│
                           │█│█│█│█│       4 candidates              │███│
                           └─┴─┴─┴─┘       700 episodes              │███│
                               │                                      │███│
                               ▼                                      │███│
                            ┌─┬─┬─┐                                  │███│
                            │█│█│█│        3 candidates              │███│
                            └─┴─┴─┘        1000 episodes             │███│
                               │                                      │███│
                               ▼                                      │███│
                             ┌─┬─┐                                   │███│
                             │█│█│         2 candidates              │███│
                             └─┴─┘         1500 episodes             │███│
                               │                                      │███│
                               ▼                                      │███│
                             ┌───┐                                   │███│
                             │███│  ◄───── 1 CHAMPION ──────────────►│███│
                             └───┘         4000 episodes             └───┘
                                           Final polish

═══════════════════════════════════════════════════════════════════════════════

   DEPTH (episodes)     100  150  200  250  300  400  500  700  1000 1500 4000
                         │    │    │    │    │    │    │    │    │    │    │
                         ▼    ▼    ▼    ▼    ▼    ▼    ▼    ▼    ▼    ▼    ▼
   ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░████
   ◄──── Shallow training ────────────────────────────── Deep training ────►
         (explore many)                                   (exploit best)
```

## Why Progressive Depth?

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                                                                             │
│   PROBLEM: Training RL is expensive. How do we find the best task graph?   │
│                                                                             │
│   ┌─────────────────────────┐     ┌─────────────────────────┐              │
│   │   Naive Approach        │     │   Our Approach          │              │
│   │                         │     │   (Progressive Depth)   │              │
│   │   Train each candidate  │     │                         │              │
│   │   for full 4000 eps     │     │   Stage 1: 16 × 100     │              │
│   │                         │     │   Stage 2: 14 × 150     │              │
│   │   16 × 4000 = 64,000    │     │   ...                   │              │
│   │   episodes total!       │     │   Stage 11: 1 × 4000    │              │
│   │                         │     │                         │              │
│   │   ❌ Wasteful           │     │   Total: ~29,000 eps    │              │
│   │                         │     │   ✓ 2x more efficient   │              │
│   └─────────────────────────┘     └─────────────────────────┘              │
│                                                                             │
│   KEY INSIGHT: Bad graphs fail fast. We don't need 4000 episodes to        │
│   know a strategy is poor - 100 episodes is enough to see the trend.       │
│                                                                             │
│   ┌────────────────────────────────────────────────────────────────────┐   │
│   │                     Reward over Episodes                            │   │
│   │                                                                     │   │
│   │  reward                                                             │   │
│   │    ▲                                                   ┌─ Best     │   │
│   │    │                                              ╱────┘  graph    │   │
│   │    │                                         ╱───╱                 │   │
│   │    │                                    ╱───╱                      │   │
│   │    │                               ╱───╱                           │   │
│   │    │         ┌─────────────────────  ◄── Good graphs improve       │   │
│   │    │    ╱────┘                                                     │   │
│   │    │   ╱                                                           │   │
│   │    │  ╱  ┌──────────────────────────  ◄── Bad graphs plateau       │   │
│   │    │ ╱  ╱                                                          │   │
│   │    │╱──╱                                                           │   │
│   │    └───────────────────────────────────────────────────────►       │   │
│   │        100      500       1000      2000      3000      4000       │   │
│   │         │                                                          │   │
│   │         └── By here we already know which graphs are promising!    │   │
│   │                                                                     │   │
│   └────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

## Evolution Between Stages

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        STAGE N → STAGE N+1 TRANSITION                        │
└─────────────────────────────────────────────────────────────────────────────┘

   After Stage N training, we have performance scores:

   ┌────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┐
   │Graph 1 │Graph 2 │Graph 3 │Graph 4 │Graph 5 │Graph 6 │Graph 7 │Graph 8 │
   │████████│██████  │████    │███████ │█████   │██      │████████│███     │
   │ 52.8   │ 45.2   │ 38.1   │ 49.3   │ 41.0   │ 28.5   │ 51.9   │ 35.2   │
   │  ⭐    │        │   ❌   │   ✓    │        │   ❌   │   ✓    │   ❌   │
   └────────┴────────┴────────┴────────┴────────┴────────┴────────┴────────┘
        │                           │                 │
        │         ┌─────────────────┘                 │
        │         │         ┌─────────────────────────┘
        ▼         ▼         ▼
   ┌─────────────────────────────────────────────────────────────────────────┐
   │                         LLM Evolution Engine                             │
   │                                                                          │
   │   ┌──────────────┐  ┌──────────────┐  ┌──────────────┐  ┌────────────┐  │
   │   │   SURVIVE    │  │  CROSSOVER   │  │   MUTATE     │  │   NOVEL    │  │
   │   │              │  │              │  │              │  │            │  │
   │   │ Top 2 graphs │  │ Combine best │  │ LLM tweaks   │  │ Fresh idea │  │
   │   │ pass through │  │ of Graph 1   │  │ promising    │  │ from LLM   │  │
   │   │ unchanged    │  │ + Graph 7    │  │ graphs       │  │            │  │
   │   │              │  │              │  │              │  │            │  │
   │   │  ┌───┐ ┌───┐ │  │    ┌───┐     │  │   ┌───┐      │  │   ┌───┐    │  │
   │   │  │ 1 │ │ 7 │ │  │    │1×7│     │  │   │1' │      │  │   │ ? │    │  │
   │   │  └───┘ └───┘ │  │    └───┘     │  │   └───┘      │  │   └───┘    │  │
   │   └──────────────┘  └──────────────┘  └──────────────┘  └────────────┘  │
   │          │                  │                 │                │        │
   └──────────┼──────────────────┼─────────────────┼────────────────┼────────┘
              │                  │                 │                │
              ▼                  ▼                 ▼                ▼
   ┌────────┬────────┬────────┬────────┬────────┬────────┐
   │Graph 1 │Graph 7 │Cross   │Mutant 1│Mutant 2│ Novel  │   ◄── Stage N+1
   │(surv)  │(surv)  │  over  │        │        │        │       candidates
   └────────┴────────┴────────┴────────┴────────┴────────┘
```

## Overview

LLM-Guided Curriculum Multi-Agent Reinforcement Learning for Overcooked.

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           LGC-MARL Training Pipeline                         │
└─────────────────────────────────────────────────────────────────────────────┘

                              ┌──────────────┐
                              │   LLM (GPT)  │
                              │              │
                              │  - Generate  │
                              │  - Mutate    │
                              │  - Crossover │
                              │  - Critique  │
                              └──────┬───────┘
                                     │
                                     ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                            Task Graph Candidates                             │
│                                                                              │
│   ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────┐       ┌─────────┐     │
│   │ Graph 1 │  │ Graph 2 │  │ Graph 3 │  │ Graph 4 │  ...  │ Graph N │     │
│   │         │  │         │  │         │  │         │       │         │     │
│   │ Agent 0:│  │ Agent 0:│  │ Agent 0:│  │ Agent 0:│       │ Agent 0:│     │
│   │ get→put │  │ get→get │  │ dish→   │  │ get→put │       │ get→put │     │
│   │ Agent 1:│  │ Agent 1:│  │ Agent 1:│  │ Agent 1:│       │ Agent 1:│     │
│   │ dish→   │  │ put→put │  │ get→put │  │ wait→   │       │ serve   │     │
│   └────┬────┘  └────┬────┘  └────┬────┘  └────┬────┘       └────┬────┘     │
│        │            │            │            │                  │          │
└────────┼────────────┼────────────┼────────────┼──────────────────┼──────────┘
         │            │            │            │                  │
         ▼            ▼            ▼            ▼                  ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                         Parallel Training (Ray)                              │
│                                                                              │
│   ┌─────────────┐  ┌─────────────┐  ┌─────────────┐      ┌─────────────┐   │
│   │   Worker 1  │  │   Worker 2  │  │   Worker 3  │ ...  │   Worker N  │   │
│   │   (0.25 GPU)│  │   (0.25 GPU)│  │   (0.25 GPU)│      │   (0.25 GPU)│   │
│   │             │  │             │  │             │      │             │   │
│   │ ┌─────────┐ │  │ ┌─────────┐ │  │ ┌─────────┐ │      │ ┌─────────┐ │   │
│   │ │Overcooked│ │  │ │Overcooked│ │  │ │Overcooked│ │      │ │Overcooked│ │   │
│   │ │   Env   │ │  │ │   Env   │ │  │ │   Env   │ │      │ │   Env   │ │   │
│   │ └────┬────┘ │  │ └────┬────┘ │  │ └────┬────┘ │      │ └────┬────┘ │   │
│   │      │      │  │      │      │  │      │      │      │      │      │   │
│   │ ┌────▼────┐ │  │ ┌────▼────┐ │  │ ┌────▼────┐ │      │ ┌────▼────┐ │   │
│   │ │  Graph  │ │  │ │  Graph  │ │  │ │  Graph  │ │      │ │  Graph  │ │   │
│   │ │Conditioned│ │  │ │Conditioned│ │  │ │Conditioned│ │      │ │Conditioned│ │   │
│   │ │ Policy  │ │  │ │ Policy  │ │  │ │ Policy  │ │      │ │ Policy  │ │   │
│   │ └────┬────┘ │  │ └────┬────┘ │  │ └────┬────┘ │      │ └────┬────┘ │   │
│   │      │      │  │      │      │  │      │      │      │      │      │   │
│   │   PPO Train │  │   PPO Train │  │   PPO Train │      │   PPO Train │   │
│   └──────┬──────┘  └──────┬──────┘  └──────┬──────┘      └──────┬──────┘   │
│          │                │                │                    │          │
└──────────┼────────────────┼────────────────┼────────────────────┼──────────┘
           │                │                │                    │
           ▼                ▼                ▼                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                            Performance Metrics                               │
│                                                                              │
│         reward=45.2       reward=38.1       reward=52.8       reward=41.0   │
│         deliveries=3      deliveries=2      deliveries=4      deliveries=2  │
│         success=85%       success=70%       success=95%       success=75%   │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
                                     │
                                     ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                          Evolution & Selection                               │
│                                                                              │
│   Stage 1: 16 candidates ──► Stage 2: 14 candidates ──► ... ──► Stage 11   │
│            100 episodes              150 episodes              4000 episodes │
│                                                                              │
│   Selection:  Top performers survive                                         │
│   Crossover:  Combine best graphs                                            │
│   Mutation:   LLM tweaks promising graphs                                    │
│   Novel:      LLM generates new ideas                                        │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

## Progressive Depth Schedule

```
Stage    Candidates    Episodes/Each    Total Episodes    Strategy
─────────────────────────────────────────────────────────────────────
  1         16             100              1,600         Wide exploration
  2         14             150              2,100         Still wide
  3         12             200              2,400         Narrowing
  4         10             250              2,500         More focus
  5          8             300              2,400         Getting serious
  6          6             400              2,400         Top performers
  7          5             500              2,500         Deeper training
  8          4             700              2,800         Narrowing
  9          3           1,000              3,000         Top 3
 10          2           1,500              3,000         Final 2
 11          1           4,000              4,000         Best, long polish
─────────────────────────────────────────────────────────────────────
                                    TOTAL: 28,700 episodes
```

## Graph-Conditioned Policy Architecture

```
                    ┌─────────────────┐
                    │  Observation    │
                    │  (per agent)    │
                    │   dim: 520      │
                    └────────┬────────┘
                             │
                             ▼
                    ┌─────────────────┐
                    │  Shared MLP     │
                    │  520 → 128      │
                    │  ReLU           │
                    │  128 → 128      │
                    │  ReLU           │
                    └────────┬────────┘
                             │
              ┌──────────────┼──────────────┐
              │              │              │
              ▼              ▼              ▼
     ┌─────────────┐  ┌─────────────┐  ┌─────────────┐
     │ Task Graph  │  │   Agent 0   │  │   Agent 1   │
     │  Encoder    │  │   Actor     │  │   Actor     │
     │             │  │   Head      │  │   Head      │
     │  GNN/MLP    │  │  128 → 6    │  │  128 → 6    │
     │  → 32 dim   │  │  (actions)  │  │  (actions)  │
     └──────┬──────┘  └──────┬──────┘  └──────┬──────┘
            │                │              │
            │         ┌──────┴──────┐       │
            │         │   Softmax   │       │
            │         └──────┬──────┘       │
            │                │              │
            ▼                ▼              ▼
     ┌─────────────────────────────────────────────┐
     │              Graph-Guided Actions            │
     │   Policy uses graph embedding to condition   │
     │   action selection on current subtask        │
     └─────────────────────────────────────────────┘
```

## Comparison: Baselines vs LGC-MARL

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                              BASELINE PPO                                    │
│                                                                              │
│   ┌──────────┐      ┌──────────┐      ┌──────────┐                         │
│   │   Obs    │ ───► │   MLP    │ ───► │ Actions  │                         │
│   └──────────┘      └──────────┘      └──────────┘                         │
│                                                                              │
│   • No coordination structure                                                │
│   • Agents learn independently                                               │
│   • No task decomposition                                                    │
└─────────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────────┐
│                           STATIC GRAPH                                       │
│                                                                              │
│   ┌──────────┐      ┌──────────┐      ┌──────────┐      ┌──────────┐       │
│   │   Obs    │ ───► │   MLP    │ ───► │  Graph   │ ───► │ Actions  │       │
│   └──────────┘      └──────────┘      │ Encoder  │      └──────────┘       │
│                                       └──────────┘                          │
│                                            ▲                                 │
│                                       ┌────┴────┐                           │
│                                       │  Fixed  │                           │
│                                       │  Graph  │                           │
│                                       └─────────┘                           │
│   • Single LLM-generated graph                                               │
│   • No evolution or adaptation                                               │
│   • Graph may be suboptimal                                                  │
└─────────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────────┐
│                            LGC-MARL (Ours)                                   │
│                                                                              │
│   ┌──────────┐      ┌──────────┐      ┌──────────┐      ┌──────────┐       │
│   │   Obs    │ ───► │   MLP    │ ───► │  Graph   │ ───► │ Actions  │       │
│   └──────────┘      └──────────┘      │ Encoder  │      └──────────┘       │
│                                       └──────────┘                          │
│                                            ▲                                 │
│                                       ┌────┴────┐                           │
│                                       │ Evolved │◄─────┐                    │
│                                       │  Graph  │      │                    │
│                                       └─────────┘      │                    │
│                                                        │                    │
│                                       ┌────────────────┴───────────────┐    │
│                                       │         LLM Evolution          │    │
│                                       │  • Generate diverse candidates │    │
│                                       │  • Mutate top performers       │    │
│                                       │  • Crossover best graphs       │    │
│                                       │  • Critique & validate         │    │
│                                       └────────────────────────────────┘    │
│                                                                              │
│   • Multiple graph candidates compete                                        │
│   • LLM evolves graphs based on performance                                  │
│   • Progressive depth: wide exploration → deep training                      │
│   • Self-improving coordination strategies                                   │
└─────────────────────────────────────────────────────────────────────────────┘
```

## Anyscale Cluster Architecture

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                          Anyscale Ray Cluster                                │
│                                                                              │
│   ┌─────────────────────────────────────────────────────────────────────┐   │
│   │                         HEAD NODE (m5.xlarge)                        │   │
│   │                            CPU only - 4 vCPU                         │   │
│   │                                                                      │   │
│   │   ┌──────────────┐  ┌──────────────┐  ┌──────────────┐             │   │
│   │   │ Ray Driver   │  │ LLM Planner  │  │   wandb/     │             │   │
│   │   │ (Coordinator)│  │ (Graph Gen)  │  │   weave      │             │   │
│   │   └──────────────┘  └──────────────┘  └──────────────┘             │   │
│   │                                                                      │   │
│   └──────────────────────────────┬──────────────────────────────────────┘   │
│                                  │                                          │
│                    ┌─────────────┼─────────────┐                            │
│                    │             │             │                            │
│                    ▼             ▼             ▼                            │
│   ┌──────────────────┐ ┌──────────────────┐ ┌──────────────────┐           │
│   │  WORKER 1        │ │  WORKER 2        │ │  WORKER 3        │  ...      │
│   │  g6.xlarge       │ │  g6.xlarge       │ │  g6.xlarge       │           │
│   │  4 vCPU + L4 GPU │ │  4 vCPU + L4 GPU │ │  4 vCPU + L4 GPU │           │
│   │                  │ │                  │ │                  │           │
│   │  ┌────┐ ┌────┐   │ │  ┌────┐ ┌────┐   │ │  ┌────┐ ┌────┐   │           │
│   │  │0.25│ │0.25│   │ │  │0.25│ │0.25│   │ │  │0.25│ │0.25│   │           │
│   │  │GPU │ │GPU │   │ │  │GPU │ │GPU │   │ │  │GPU │ │GPU │   │           │
│   │  └────┘ └────┘   │ │  └────┘ └────┘   │ │  └────┘ └────┘   │           │
│   │  ┌────┐ ┌────┐   │ │  ┌────┐ ┌────┐   │ │  ┌────┐ ┌────┐   │           │
│   │  │0.25│ │0.25│   │ │  │0.25│ │0.25│   │ │  │0.25│ │0.25│   │           │
│   │  │GPU │ │GPU │   │ │  │GPU │ │GPU │   │ │  │GPU │ │GPU │   │           │
│   │  └────┘ └────┘   │ │  └────┘ └────┘   │ │  └────┘ └────┘   │           │
│   │                  │ │                  │ │                  │           │
│   │  4 tasks/worker  │ │  4 tasks/worker  │ │  4 tasks/worker  │           │
│   └──────────────────┘ └──────────────────┘ └──────────────────┘           │
│                                                                              │
│   Total: 4 workers × 4 tasks = 16 parallel training runs                    │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

## Task Graph Example

```
┌─────────────────────────────────────────────────────────────────┐
│                    Onion Soup Task Graph                         │
│                                                                  │
│   Agent 0 (Chef)                    Agent 1 (Runner)            │
│   ─────────────                     ──────────────               │
│                                                                  │
│   ┌─────────────┐                   ┌─────────────┐             │
│   │ get_onion_1 │                   │ get_onion_2 │             │
│   └──────┬──────┘                   └──────┬──────┘             │
│          │                                 │                     │
│          ▼                                 ▼                     │
│   ┌─────────────┐                   ┌─────────────┐             │
│   │ put_in_pot  │                   │ put_in_pot  │             │
│   └──────┬──────┘                   └──────┬──────┘             │
│          │                                 │                     │
│          ▼                                 │                     │
│   ┌─────────────┐                          │                     │
│   │ get_onion_3 │                          │                     │
│   └──────┬──────┘                          │                     │
│          │                                 │                     │
│          ▼                                 │                     │
│   ┌─────────────┐                          │                     │
│   │ put_in_pot  │◄─────────────────────────┘                     │
│   └──────┬──────┘                                                │
│          │                                                       │
│          ▼                                                       │
│   ┌─────────────┐                   ┌─────────────┐             │
│   │wait_cooking │                   │  get_dish   │             │
│   └──────┬──────┘                   └──────┬──────┘             │
│          │                                 │                     │
│          └─────────────┬───────────────────┘                     │
│                        ▼                                         │
│                 ┌─────────────┐                                  │
│                 │ plate_soup  │                                  │
│                 └──────┬──────┘                                  │
│                        │                                         │
│                        ▼                                         │
│                 ┌─────────────┐                                  │
│                 │   serve     │                                  │
│                 └─────────────┘                                  │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```
